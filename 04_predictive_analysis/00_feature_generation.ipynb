{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, gc\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import aggregated trips\n",
    "trips_aggregated_df_init = pd.read_parquet(TRIPS_GROUPED_SPATIO_TEMPORAL_PATH)\n",
    "trips_aggregated_df = trips_aggregated_df_init[\n",
    "    (trips_aggregated_df_init['h3_res'] != ORIGIN_DESTINATION_H3_RESOLUTION) |\n",
    "    (trips_aggregated_df_init['time_interval_length'] != ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH)\n",
    "]\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_init[\n",
    "    (trips_aggregated_df_init['h3_res'] == ORIGIN_DESTINATION_H3_RESOLUTION) & \n",
    "    (trips_aggregated_df_init['time_interval_length'] == ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH)\n",
    "]\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_reduced.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in the demand dataset for all h3 resolutions and all time intervals: 4253147\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of entries in the demand dataset for all h3 resolutions and all time intervals: {trips_aggregated_df_init.index.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# trips_aggregated_df['hour_sin'] = np.sin(trips_aggregated_df.hour*(2.*np.pi/24))\n",
    "# trips_aggregated_df['hour_cos'] = np.cos(trips_aggregated_df.hour*(2.*np.pi/24))\n",
    "# # m\n",
    "# trips_aggregated_df['month_sin'] = np.sin((trips_aggregated_df.month-1)*(2.*np.pi/12))\n",
    "# trips_aggregated_df['month_cos'] = np.cos((trips_aggregated_df.month-1)*(2.*np.pi/12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>mean_mean_wind_speed</th>\n",
       "      <th>mean_total_cloud_cover</th>\n",
       "      <th>sum_precipitation</th>\n",
       "      <th>time_interval_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MESS_DATUM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>7.398438</td>\n",
       "      <td>7.398438</td>\n",
       "      <td>7.398438</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>7.699219</td>\n",
       "      <td>7.699219</td>\n",
       "      <td>7.699219</td>\n",
       "      <td>2.900391</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     min_temperature  max_temperature  mean_temperature  \\\n",
       "MESS_DATUM                                                                \n",
       "2019-01-01 00:00:00         7.398438         7.398438          7.398438   \n",
       "2019-01-01 01:00:00         7.699219         7.699219          7.699219   \n",
       "\n",
       "                     mean_mean_wind_speed  mean_total_cloud_cover  \\\n",
       "MESS_DATUM                                                          \n",
       "2019-01-01 00:00:00              2.800781                     8.0   \n",
       "2019-01-01 01:00:00              2.900391                     8.0   \n",
       "\n",
       "                     sum_precipitation  time_interval_length  \n",
       "MESS_DATUM                                                    \n",
       "2019-01-01 00:00:00                0.0                     1  \n",
       "2019-01-01 01:00:00                0.0                     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the weather dataframe, reduce data types\n",
    "weather_df = pd.read_parquet(WEATHER_AGGR_TEMPORAL_PATH)\n",
    "weather_df = weather_df.astype(np.float16)\n",
    "weather_df['time_interval_length'] = weather_df.time_interval_length.astype(np.uint8)\n",
    "weather_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weather data with trips data\n",
    "trips_aggregated_df = pd.merge(trips_aggregated_df, weather_df,  how='left', \n",
    "                    left_on=['datetime_start_floored','time_interval_length'],\n",
    "                    right_on = ['MESS_DATUM','time_interval_length'])\n",
    "\n",
    "trips_aggregated_df_reduced = pd.merge(trips_aggregated_df_reduced, weather_df,  how='left', \n",
    "                    left_on=['datetime_start_floored','time_interval_length'],\n",
    "                    right_on = ['MESS_DATUM','time_interval_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load poi data and reduce datatypes\n",
    "hexagons_with_pois_df = pd.read_parquet(HEXAGON_WITH_POIS_PATH)\n",
    "hexagons_with_pois_df = hexagons_with_pois_df.drop(columns=[\"hex_and_neighbors\"])\n",
    "hexagons_with_pois_df = hexagons_with_pois_df.astype({\n",
    "    \"h3_res\": np.uint16,\n",
    "    \"sustenance_poi\": np.uint16,\n",
    "    \"public_transport_poi\": np.uint16,\n",
    "    \"education_poi\": np.uint16,\n",
    "    \"arts_and_culture_poi\": np.uint16,\n",
    "    \"sports_poi\": np.uint16,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start_floored</th>\n",
       "      <th>start_hex_id</th>\n",
       "      <th>end_hex_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>h3_res</th>\n",
       "      <th>time_interval_length</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>mean_mean_wind_speed</th>\n",
       "      <th>mean_total_cloud_cover</th>\n",
       "      <th>sum_precipitation</th>\n",
       "      <th>sustenance_poi_start</th>\n",
       "      <th>public_transport_poi_start</th>\n",
       "      <th>education_poi_start</th>\n",
       "      <th>arts_and_culture_poi_start</th>\n",
       "      <th>sports_poi_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-5.402344</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>0.083313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a164ffffff</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-5.402344</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>0.083313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_start_floored     start_hex_id       end_hex_id  demand  h3_res  \\\n",
       "0             2019-01-20  871f1a160ffffff  871f1a160ffffff       4       7   \n",
       "1             2019-01-20  871f1a160ffffff  871f1a164ffffff       5       7   \n",
       "\n",
       "   time_interval_length  min_temperature  max_temperature  mean_temperature  \\\n",
       "0                    24        -9.101562        -0.199951         -5.402344   \n",
       "1                    24        -9.101562        -0.199951         -5.402344   \n",
       "\n",
       "   mean_mean_wind_speed  mean_total_cloud_cover  sum_precipitation  \\\n",
       "0              0.854004                0.083313                0.0   \n",
       "1              0.854004                0.083313                0.0   \n",
       "\n",
       "   sustenance_poi_start  public_transport_poi_start  education_poi_start  \\\n",
       "0                   355                         309                   54   \n",
       "1                   355                         309                   54   \n",
       "\n",
       "   arts_and_culture_poi_start  sports_poi_start  \n",
       "0                          11                15  \n",
       "1                          11                15  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add poi use data as feature of the start location\n",
    "trips_aggregated_df = pd.merge(trips_aggregated_df, hexagons_with_pois_df.drop(columns=[\"h3_res\"]), left_on=\"start_hex_id\", right_on=\"hex\")\n",
    "trips_aggregated_df = trips_aggregated_df.drop(columns={\"hex\"})\n",
    "\n",
    "# add '_start' suffix to poi columns\n",
    "trips_aggregated_df = trips_aggregated_df.rename(columns={\n",
    "    \"sustenance_poi\": \"sustenance_poi_start\",\n",
    "    \"public_transport_poi\": \"public_transport_poi_start\",\n",
    "    \"education_poi\": \"education_poi_start\",\n",
    "    \"arts_and_culture_poi\": \"arts_and_culture_poi_start\",\n",
    "    \"sports_poi\": \"sports_poi_start\",\n",
    "})\n",
    "\n",
    "# add poi use data as feature of the start location\n",
    "trips_aggregated_df_reduced = pd.merge(trips_aggregated_df_reduced, hexagons_with_pois_df.drop(columns=[\"h3_res\"]), left_on=\"start_hex_id\", right_on=\"hex\")\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_reduced.drop(columns={\"hex\"})\n",
    "\n",
    "# add '_start' suffix to poi columns\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_reduced.rename(columns={\n",
    "    \"sustenance_poi\": \"sustenance_poi_start\",\n",
    "    \"public_transport_poi\": \"public_transport_poi_start\",\n",
    "    \"education_poi\": \"education_poi_start\",\n",
    "    \"arts_and_culture_poi\": \"arts_and_culture_poi_start\",\n",
    "    \"sports_poi\": \"sports_poi_start\",\n",
    "})\n",
    "trips_aggregated_df_reduced.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime_start_floored', 'start_hex_id', 'end_hex_id', 'demand',\n",
       "       'h3_res', 'time_interval_length', 'min_temperature', 'max_temperature',\n",
       "       'mean_temperature', 'mean_mean_wind_speed', 'mean_total_cloud_cover',\n",
       "       'sum_precipitation', 'sustenance_poi_start',\n",
       "       'public_transport_poi_start', 'education_poi_start',\n",
       "       'arts_and_culture_poi_start', 'sports_poi_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_aggregated_df_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start_floored</th>\n",
       "      <th>start_hex_id</th>\n",
       "      <th>end_hex_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>h3_res_x</th>\n",
       "      <th>time_interval_length</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>mean_mean_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>sustenance_poi_start</th>\n",
       "      <th>public_transport_poi_start</th>\n",
       "      <th>education_poi_start</th>\n",
       "      <th>arts_and_culture_poi_start</th>\n",
       "      <th>sports_poi_start</th>\n",
       "      <th>sustenance_poi_end</th>\n",
       "      <th>public_transport_poi_end</th>\n",
       "      <th>education_poi_end</th>\n",
       "      <th>arts_and_culture_poi_end</th>\n",
       "      <th>sports_poi_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-5.402344</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>...</td>\n",
       "      <td>355</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>355</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-6.507812</td>\n",
       "      <td>0.916504</td>\n",
       "      <td>...</td>\n",
       "      <td>355</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>355</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_start_floored     start_hex_id       end_hex_id  demand  h3_res_x  \\\n",
       "0             2019-01-20  871f1a160ffffff  871f1a160ffffff       4         7   \n",
       "1             2019-01-21  871f1a160ffffff  871f1a160ffffff       8         7   \n",
       "\n",
       "   time_interval_length  min_temperature  max_temperature  mean_temperature  \\\n",
       "0                    24        -9.101562        -0.199951         -5.402344   \n",
       "1                    24        -9.101562        -3.300781         -6.507812   \n",
       "\n",
       "   mean_mean_wind_speed  ...  sustenance_poi_start  \\\n",
       "0              0.854004  ...                   355   \n",
       "1              0.916504  ...                   355   \n",
       "\n",
       "   public_transport_poi_start  education_poi_start  \\\n",
       "0                         309                   54   \n",
       "1                         309                   54   \n",
       "\n",
       "   arts_and_culture_poi_start  sports_poi_start  sustenance_poi_end  \\\n",
       "0                          11                15                 355   \n",
       "1                          11                15                 355   \n",
       "\n",
       "   public_transport_poi_end  education_poi_end  arts_and_culture_poi_end  \\\n",
       "0                       309                 54                        11   \n",
       "1                       309                 54                        11   \n",
       "\n",
       "   sports_poi_end  \n",
       "0              15  \n",
       "1              15  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add poi use data as feature of the end location\n",
    "trips_aggregated_df_reduced = pd.merge(trips_aggregated_df_reduced, hexagons_with_pois_df, left_on=\"end_hex_id\", right_on=\"hex\")\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_reduced.drop(columns={\"hex\", \"h3_res_y\"})\n",
    "\n",
    "# add '_end' suffix to poi columns\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_reduced.rename(\n",
    "    columns={\n",
    "        \"sustenance_poi\": \"sustenance_poi_end\",\n",
    "        \"public_transport_poi\": \"public_transport_poi_end\",\n",
    "        \"education_poi\": \"education_poi_end\",\n",
    "        \"arts_and_culture_poi\": \"arts_and_culture_poi_end\",\n",
    "        \"sports_poi\": \"sports_poi_end\",\n",
    "    }\n",
    ")\n",
    "trips_aggregated_df_reduced.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del hexagons_with_pois_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>land_use</th>\n",
       "      <th>land_use_1</th>\n",
       "      <th>land_use_2</th>\n",
       "      <th>land_use_3</th>\n",
       "      <th>land_use_4</th>\n",
       "      <th>land_use_5</th>\n",
       "      <th>land_use_6</th>\n",
       "      <th>land_use_7</th>\n",
       "      <th>land_use_8</th>\n",
       "      <th>land_use_9</th>\n",
       "      <th>land_use_10</th>\n",
       "      <th>...</th>\n",
       "      <th>land_use_13</th>\n",
       "      <th>land_use_14</th>\n",
       "      <th>land_use_15</th>\n",
       "      <th>land_use_16</th>\n",
       "      <th>land_use_17</th>\n",
       "      <th>land_use_18</th>\n",
       "      <th>land_use_19</th>\n",
       "      <th>land_use_20</th>\n",
       "      <th>land_use_21</th>\n",
       "      <th>land_use_22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hexagon_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>871f1a140ffffff</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871f1a144ffffff</th>\n",
       "      <td>0.148926</td>\n",
       "      <td>0.155518</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.084351</td>\n",
       "      <td>0.135986</td>\n",
       "      <td>0.058533</td>\n",
       "      <td>0.071045</td>\n",
       "      <td>0.082703</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.031219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "land_use         land_use_1  land_use_2  land_use_3  land_use_4  land_use_5  \\\n",
       "hexagon_id                                                                    \n",
       "871f1a140ffffff    0.000000    0.000000    0.000000    0.000000    0.006058   \n",
       "871f1a144ffffff    0.148926    0.155518    0.016571    0.084351    0.135986   \n",
       "\n",
       "land_use         land_use_6  land_use_7  land_use_8  land_use_9  land_use_10  \\\n",
       "hexagon_id                                                                     \n",
       "871f1a140ffffff    0.000000    0.019272    0.015480    0.000000     0.319092   \n",
       "871f1a144ffffff    0.058533    0.071045    0.082703    0.004414     0.031219   \n",
       "\n",
       "land_use         ...  land_use_13  land_use_14  land_use_15  land_use_16  \\\n",
       "hexagon_id       ...                                                       \n",
       "871f1a140ffffff  ...     0.000000          0.0          0.0     0.007874   \n",
       "871f1a144ffffff  ...     0.000406          0.0          0.0     0.000000   \n",
       "\n",
       "land_use         land_use_17  land_use_18  land_use_19  land_use_20  \\\n",
       "hexagon_id                                                            \n",
       "871f1a140ffffff          0.0     0.000000          0.0     0.001923   \n",
       "871f1a144ffffff          0.0     0.004196          0.0     0.070251   \n",
       "\n",
       "land_use         land_use_21  land_use_22  \n",
       "hexagon_id                                 \n",
       "871f1a140ffffff     0.008865          0.0  \n",
       "871f1a144ffffff     0.000000          0.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load land use data and reduce data types\n",
    "hexagons_with_land_use_df = pd.read_parquet(HEXAGONS_WITH_LAND_USE_PATH)\n",
    "hexagons_with_land_use_df = hexagons_with_land_use_df.astype(np.float16)\n",
    "hexagons_with_land_use_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start_floored</th>\n",
       "      <th>start_hex_id</th>\n",
       "      <th>end_hex_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>h3_res_x</th>\n",
       "      <th>time_interval_length</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>mean_mean_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>start_land_use_13</th>\n",
       "      <th>start_land_use_14</th>\n",
       "      <th>start_land_use_15</th>\n",
       "      <th>start_land_use_16</th>\n",
       "      <th>start_land_use_17</th>\n",
       "      <th>start_land_use_18</th>\n",
       "      <th>start_land_use_19</th>\n",
       "      <th>start_land_use_20</th>\n",
       "      <th>start_land_use_21</th>\n",
       "      <th>start_land_use_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-5.402344</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-6.507812</td>\n",
       "      <td>0.916504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_start_floored     start_hex_id       end_hex_id  demand  h3_res_x  \\\n",
       "0             2019-01-20  871f1a160ffffff  871f1a160ffffff       4         7   \n",
       "1             2019-01-21  871f1a160ffffff  871f1a160ffffff       8         7   \n",
       "\n",
       "   time_interval_length  min_temperature  max_temperature  mean_temperature  \\\n",
       "0                    24        -9.101562        -0.199951         -5.402344   \n",
       "1                    24        -9.101562        -3.300781         -6.507812   \n",
       "\n",
       "   mean_mean_wind_speed  ...  start_land_use_13  start_land_use_14  \\\n",
       "0              0.854004  ...           0.001766                0.0   \n",
       "1              0.916504  ...           0.001766                0.0   \n",
       "\n",
       "   start_land_use_15  start_land_use_16  start_land_use_17  start_land_use_18  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   start_land_use_19  start_land_use_20  start_land_use_21  start_land_use_22  \n",
       "0                0.0           0.100342                0.0                0.0  \n",
       "1                0.0           0.100342                0.0                0.0  \n",
       "\n",
       "[2 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add land use data as feature of the start location\n",
    "trips_aggregated_df = pd.merge(trips_aggregated_df, hexagons_with_land_use_df.add_prefix(\"start_\"), left_on=\"start_hex_id\", right_on=\"hexagon_id\")\n",
    "trips_aggregated_df_reduced = pd.merge(trips_aggregated_df_reduced, hexagons_with_land_use_df.add_prefix(\"start_\"), left_on=\"start_hex_id\", right_on=\"hexagon_id\")\n",
    "trips_aggregated_df_reduced.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start_floored</th>\n",
       "      <th>start_hex_id</th>\n",
       "      <th>end_hex_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>h3_res_x</th>\n",
       "      <th>time_interval_length</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>mean_temperature</th>\n",
       "      <th>mean_mean_wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>end_land_use_13</th>\n",
       "      <th>end_land_use_14</th>\n",
       "      <th>end_land_use_15</th>\n",
       "      <th>end_land_use_16</th>\n",
       "      <th>end_land_use_17</th>\n",
       "      <th>end_land_use_18</th>\n",
       "      <th>end_land_use_19</th>\n",
       "      <th>end_land_use_20</th>\n",
       "      <th>end_land_use_21</th>\n",
       "      <th>end_land_use_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-5.402344</td>\n",
       "      <td>0.854004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>871f1a160ffffff</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.101562</td>\n",
       "      <td>-3.300781</td>\n",
       "      <td>-6.507812</td>\n",
       "      <td>0.916504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  datetime_start_floored     start_hex_id       end_hex_id  demand  h3_res_x  \\\n",
       "0             2019-01-20  871f1a160ffffff  871f1a160ffffff       4         7   \n",
       "1             2019-01-21  871f1a160ffffff  871f1a160ffffff       8         7   \n",
       "\n",
       "   time_interval_length  min_temperature  max_temperature  mean_temperature  \\\n",
       "0                    24        -9.101562        -0.199951         -5.402344   \n",
       "1                    24        -9.101562        -3.300781         -6.507812   \n",
       "\n",
       "   mean_mean_wind_speed  ...  end_land_use_13  end_land_use_14  \\\n",
       "0              0.854004  ...         0.001766              0.0   \n",
       "1              0.916504  ...         0.001766              0.0   \n",
       "\n",
       "   end_land_use_15  end_land_use_16  end_land_use_17  end_land_use_18  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   end_land_use_19  end_land_use_20  end_land_use_21  end_land_use_22  \n",
       "0              0.0         0.100342              0.0              0.0  \n",
       "1              0.0         0.100342              0.0              0.0  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add land use data as feature of the end location\n",
    "trips_aggregated_df_reduced = pd.merge(trips_aggregated_df_reduced, hexagons_with_land_use_df.add_prefix(\"end_\"), left_on=\"end_hex_id\", right_on=\"hexagon_id\")\n",
    "trips_aggregated_df_reduced.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del hexagons_with_land_use_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955.1518306732178\n",
      "13.412040710449219\n"
     ]
    }
   ],
   "source": [
    "print(trips_aggregated_df.memory_usage(index=True, deep=True).sum() / 1024**2)\n",
    "print(trips_aggregated_df_reduced.memory_usage(index=True, deep=True).sum() / 1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_hex_id_map = dict(enumerate(trips_aggregated_df.start_hex_id.unique()))\n",
    "start_hex_id_map = {v: k for k, v in start_hex_id_map.items()}\n",
    "\n",
    "reduced_start_hex_id_map = dict(enumerate(trips_aggregated_df_reduced.start_hex_id.unique()))\n",
    "reduced_end_hex_id_map = dict(enumerate(trips_aggregated_df_reduced.end_hex_id.unique()))\n",
    "reduced_start_hex_id_map = {v: k for k, v in reduced_start_hex_id_map.items()}\n",
    "reduced_end_hex_id_map = {v: k for k, v in reduced_end_hex_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_aggregated_df[\"start_hex_id\"] = trips_aggregated_df[\"start_hex_id\"].map(start_hex_id_map).astype(np.uint16)\n",
    "\n",
    "trips_aggregated_df_reduced[\"start_hex_id\"] = trips_aggregated_df_reduced[\"start_hex_id\"].map(reduced_start_hex_id_map).astype(np.uint16)\n",
    "trips_aggregated_df_reduced[\"end_hex_id\"] = trips_aggregated_df_reduced[\"end_hex_id\"].map(reduced_end_hex_id_map).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all model data in one file\n",
    "trips_aggregated_df.to_feather(MODEL_DATA_PATH)\n",
    "trips_aggregated_df_reduced.to_feather(REDUCED_MODEL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features_to_model_data(model_data):\n",
    "    # add time features\n",
    "    model_data['hour'] = model_data.datetime_start_floored.dt.hour\n",
    "    model_data['weekday'] = model_data.datetime_start_floored.dt.weekday\n",
    "    model_data['month'] = model_data.datetime_start_floored.dt.month\n",
    "\n",
    "    # convert time features to dummy variables (one-hot encoding) and replace the original features\n",
    "    hour_dummies = pd.get_dummies(model_data['hour']).add_prefix('hour_')\n",
    "    weekday_dummies = pd.get_dummies(model_data['weekday']).add_prefix('weekday_')\n",
    "    month_dummies = pd.get_dummies(model_data['month']).add_prefix('month_')\n",
    "\n",
    "    model_data.drop(['hour', 'weekday', 'month'], axis=1, inplace=True)\n",
    "    model_data = pd.concat([model_data, hour_dummies, weekday_dummies, month_dummies], axis=1)\n",
    "\n",
    "    del hour_dummies, weekday_dummies, month_dummies\n",
    "    gc.collect()\n",
    "    # remove datetime_start_floored column as it won't be needed anymore\n",
    "    model_data = model_data.drop(columns=['datetime_start_floored'])\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invalid_cols(df):\n",
    "    cols = df.sum().apply(lambda x: np.isinf(x))\n",
    "    return cols[cols].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(MODEL_DATA_DIR_PATH):\n",
    "\tos.makedirs(MODEL_DATA_DIR_PATH)\n",
    "\n",
    "# store model data for each time and hex resolution in one file\n",
    "# additionally create dummies for start and end hexagons  \n",
    "for h3_res in CALC_H3_RESOLUTIONS:\n",
    "    for t in CALC_TIME_INTERVAL_LENGTHS:\n",
    "        if (h3_res == ORIGIN_DESTINATION_H3_RESOLUTION and t == ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH): continue\n",
    "\n",
    "        model_data = trips_aggregated_df[\n",
    "            (trips_aggregated_df.h3_res == h3_res) & (trips_aggregated_df.time_interval_length == t)\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "        if t > 5:\n",
    "            model_data = model_data.drop(columns=[\"mean_temperature\"])\n",
    "        else:\n",
    "            model_data = model_data.drop(columns=[\"min_temperature\", \"max_temperature\"])\n",
    "\n",
    "        model_data = add_time_features_to_model_data(model_data)\n",
    "\n",
    "        start_hex_dummies = pd.get_dummies(model_data.start_hex_id, prefix=\"start_\")\n",
    "        model_data = pd.concat([model_data, start_hex_dummies], axis=1)\n",
    "        model_data = model_data.drop(columns=['start_hex_id', 'end_hex_id', 'h3_res', 'time_interval_length'])\n",
    "        \n",
    "        invalid_cols = get_invalid_cols(model_data)\n",
    "\n",
    "        # check if sum of all values in each column can be represented by the dtype of the column\n",
    "        # if this is not the case we cannot scale the data as calculated the mean will return erroneous values\n",
    "        if len(invalid_cols) > 0:\n",
    "            for col in invalid_cols:\n",
    "                if model_data[col].dtype != np.float16:\n",
    "                    raise ValueError(\"Unexpected dtype for column {}. Expected float16, got {}\".format(col, model_data[col].dtype))\n",
    "                model_data[col] = model_data[col].astype(np.float32)\n",
    "        \n",
    "        invalid_cols = get_invalid_cols(model_data)\n",
    "        if len(invalid_cols) > 0:\n",
    "            raise ValueError(\"Invalid columns remaining\")\n",
    "\n",
    "\n",
    "        model_data.to_feather(os.path.join(MODEL_DATA_DIR_PATH, f\"{h3_res}_{t}.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if t > ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH:\n",
    "    trips_aggregated_df_reduced = trips_aggregated_df_reduced.drop(columns=[\"mean_temperature\"])\n",
    "else:\n",
    "    trips_aggregated_df_reduced = trips_aggregated_df_reduced.drop(columns=[\"min_temperature\", \"max_temperature\"])\n",
    "\n",
    "trips_aggregated_df_reduced = add_time_features_to_model_data(trips_aggregated_df_reduced)\n",
    "\n",
    "start_hex_dummies = pd.get_dummies(trips_aggregated_df_reduced.start_hex_id, prefix=\"start_\")\n",
    "end_hex_dummies = pd.get_dummies(trips_aggregated_df_reduced.end_hex_id, prefix=\"end_\")\n",
    "trips_aggregated_df_reduced = pd.concat([trips_aggregated_df_reduced, start_hex_dummies, end_hex_dummies], axis=1)\n",
    "trips_aggregated_df_reduced = trips_aggregated_df_reduced.drop(columns=['start_hex_id', 'end_hex_id', 'h3_res_x', 'time_interval_length'])\n",
    "\n",
    "trips_aggregated_df_reduced.to_feather(os.path.join(MODEL_DATA_DIR_PATH, f\"{ORIGIN_DESTINATION_H3_RESOLUTION}_{ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH}.feather\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "480189c8b893ba0e665d676e4d8fbaa7064789f8cb0c8dbdf4a412ac1da4cf12"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AAA_MAGMA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
