{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os, gc\n",
        "\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from modules.config import *\n",
        "from modules.preprocessing import reindex_on_full_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_aggregated_df_init = pd.read_parquet(TRIPS_GROUPED_SPATIO_TEMPORAL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig = trips_aggregated_df_init\n",
        "trips_orig_dest = trips_aggregated_df_init[\n",
        "    (trips_aggregated_df_init['h3_res'] == ORIGIN_DESTINATION_H3_RESOLUTION) & \n",
        "    (trips_aggregated_df_init['time_interval_length'] == ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH)\n",
        "]\n",
        "# trips_orig_dest = trips_orig_dest.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig = (\n",
        "    trips_orig.groupby([\"datetime_start_floored\", \"start_hex_id\"])\n",
        "    .agg({\"demand\": \"sum\", \"h3_res\": \"max\", \"time_interval_length\": \"max\"})\n",
        "    .reset_index()\n",
        ")\n",
        "trips_orig = trips_orig.rename(\n",
        "\tcolumns={\"datetime_start_floored\": \"datetime\", \"start_hex_id\": \"hex_id\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig_dest = trips_orig_dest.rename(columns={\"datetime_start_floored\": \"datetime\"})\n",
        "trips_orig_dest = trips_orig_dest.set_index([\"datetime\", \"start_hex_id\", \"end_hex_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig_dest = reindex_on_full_index(\n",
        "    trips_orig_dest, ORIGIN_DESTINATION_H3_RESOLUTION, ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH, start_and_end=True\n",
        ").reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c08ac3ed18a42739c4dd0a4ae0cc073",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trips_orig = trips_orig.set_index([\"datetime\", \"hex_id\"])\n",
        "full_trips = []\n",
        "\n",
        "for h3_res, time_interval_length in tqdm(\n",
        "    list(itertools.product(CALC_H3_RESOLUTIONS, CALC_TIME_INTERVAL_LENGTHS))\n",
        "):\n",
        "    trips = trips_orig[(trips_orig['h3_res'] == h3_res) & (trips_orig['time_interval_length'] == time_interval_length)]\n",
        "    full_trips.append(reindex_on_full_index(trips, h3_res, time_interval_length))\n",
        "\n",
        "trips_orig = pd.concat(full_trips)\n",
        "del full_trips\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig = trips_orig.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "availability_df = pd.read_parquet(AVAILABILITY_PATH)\n",
        "availability_df = availability_df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of entries in the demand dataset for all h3 resolutions and all time intervals: 13098911\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of entries in the demand dataset for all h3 resolutions and all time intervals: {trips_orig.index.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_temperature</th>\n",
              "      <th>max_temperature</th>\n",
              "      <th>mean_temperature</th>\n",
              "      <th>mean_mean_wind_speed</th>\n",
              "      <th>mean_total_cloud_cover</th>\n",
              "      <th>sum_precipitation</th>\n",
              "      <th>time_interval_length</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MESS_DATUM</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>7.398438</td>\n",
              "      <td>7.398438</td>\n",
              "      <td>7.398438</td>\n",
              "      <td>2.800781</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>7.699219</td>\n",
              "      <td>7.699219</td>\n",
              "      <td>7.699219</td>\n",
              "      <td>2.900391</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     min_temperature  max_temperature  mean_temperature  \\\n",
              "MESS_DATUM                                                                \n",
              "2019-01-01 00:00:00         7.398438         7.398438          7.398438   \n",
              "2019-01-01 01:00:00         7.699219         7.699219          7.699219   \n",
              "\n",
              "                     mean_mean_wind_speed  mean_total_cloud_cover  \\\n",
              "MESS_DATUM                                                          \n",
              "2019-01-01 00:00:00              2.800781                     8.0   \n",
              "2019-01-01 01:00:00              2.900391                     8.0   \n",
              "\n",
              "                     sum_precipitation  time_interval_length  \n",
              "MESS_DATUM                                                    \n",
              "2019-01-01 00:00:00                0.0                     1  \n",
              "2019-01-01 01:00:00                0.0                     1  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the weather dataframe, reduce data types\n",
        "weather_df = pd.read_parquet(WEATHER_AGGR_TEMPORAL_PATH)\n",
        "weather_df = weather_df.astype(np.float16)\n",
        "weather_df['time_interval_length'] = weather_df.time_interval_length.astype(np.uint8)\n",
        "weather_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_weather_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    return pd.merge(\n",
        "        df,\n",
        "        weather_df,\n",
        "        how=\"left\",\n",
        "        left_on=[\"datetime\", \"time_interval_length\"],\n",
        "        right_on=[\"MESS_DATUM\", \"time_interval_length\"],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge weather data with trips data\n",
        "trips_orig = add_weather_data(trips_orig)\n",
        "trips_orig_dest = add_weather_data(trips_orig_dest)\n",
        "availability_df = add_weather_data(availability_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "del weather_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load poi data and reduce datatypes\n",
        "hexagons_with_pois_df = pd.read_parquet(HEXAGON_WITH_POIS_PATH)\n",
        "hexagons_with_pois_df = hexagons_with_pois_df.drop(columns=[\"hex_and_neighbors\"])\n",
        "hexagons_with_pois_df = hexagons_with_pois_df.astype({\n",
        "    \"h3_res\": np.uint16,\n",
        "    \"sustenance_poi\": np.uint16,\n",
        "    \"public_transport_poi\": np.uint16,\n",
        "    \"education_poi\": np.uint16,\n",
        "    \"arts_and_culture_poi\": np.uint16,\n",
        "    \"sports_poi\": np.uint16,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "hexagons_with_pois_df = hexagons_with_pois_df.drop(columns=[\"h3_res\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_poi_data(df: pd.DataFrame, on=\"hex_id\", suffix: str = None) -> pd.DataFrame:\n",
        "    df = pd.merge(\n",
        "        df,\n",
        "        hexagons_with_pois_df.add_suffix(suffix) if suffix else hexagons_with_pois_df,\n",
        "        left_on=on,\n",
        "        right_on=f\"hex{suffix}\" if suffix else \"hex\",\n",
        "    )\n",
        "    df = df.drop(columns=[\"hex\" + suffix if suffix else \"hex\"])\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig = add_poi_data(trips_orig)\n",
        "trips_orig_dest = add_poi_data(trips_orig_dest, on=\"start_hex_id\", suffix=\"_start\")\n",
        "trips_orig_dest = add_poi_data(trips_orig_dest, on=\"end_hex_id\", suffix=\"_end\")\n",
        "availability_df = add_poi_data(availability_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['datetime', 'start_hex_id', 'end_hex_id', 'demand', 'h3_res',\n",
              "       'time_interval_length', 'min_temperature', 'max_temperature',\n",
              "       'mean_temperature', 'mean_mean_wind_speed', 'mean_total_cloud_cover',\n",
              "       'sum_precipitation', 'hex_start', 'sustenance_poi_start',\n",
              "       'public_transport_poi_start', 'education_poi_start',\n",
              "       'arts_and_culture_poi_start', 'sports_poi_start', 'hex_end',\n",
              "       'sustenance_poi_end', 'public_transport_poi_end', 'education_poi_end',\n",
              "       'arts_and_culture_poi_end', 'sports_poi_end'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trips_orig_dest.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "del hexagons_with_pois_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>land_use</th>\n",
              "      <th>hexagon_id</th>\n",
              "      <th>land_use_1</th>\n",
              "      <th>land_use_2</th>\n",
              "      <th>land_use_3</th>\n",
              "      <th>land_use_4</th>\n",
              "      <th>land_use_5</th>\n",
              "      <th>land_use_6</th>\n",
              "      <th>land_use_7</th>\n",
              "      <th>land_use_8</th>\n",
              "      <th>land_use_9</th>\n",
              "      <th>...</th>\n",
              "      <th>land_use_13</th>\n",
              "      <th>land_use_14</th>\n",
              "      <th>land_use_15</th>\n",
              "      <th>land_use_16</th>\n",
              "      <th>land_use_17</th>\n",
              "      <th>land_use_18</th>\n",
              "      <th>land_use_19</th>\n",
              "      <th>land_use_20</th>\n",
              "      <th>land_use_21</th>\n",
              "      <th>land_use_22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>871f1a140ffffff</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019272</td>\n",
              "      <td>0.015480</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001923</td>\n",
              "      <td>0.008865</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>871f1a144ffffff</td>\n",
              "      <td>0.148926</td>\n",
              "      <td>0.155518</td>\n",
              "      <td>0.016571</td>\n",
              "      <td>0.084351</td>\n",
              "      <td>0.135986</td>\n",
              "      <td>0.058533</td>\n",
              "      <td>0.071045</td>\n",
              "      <td>0.082703</td>\n",
              "      <td>0.004414</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070251</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "land_use       hexagon_id  land_use_1  land_use_2  land_use_3  land_use_4  \\\n",
              "0         871f1a140ffffff    0.000000    0.000000    0.000000    0.000000   \n",
              "1         871f1a144ffffff    0.148926    0.155518    0.016571    0.084351   \n",
              "\n",
              "land_use  land_use_5  land_use_6  land_use_7  land_use_8  land_use_9  ...  \\\n",
              "0           0.006058    0.000000    0.019272    0.015480    0.000000  ...   \n",
              "1           0.135986    0.058533    0.071045    0.082703    0.004414  ...   \n",
              "\n",
              "land_use  land_use_13  land_use_14  land_use_15  land_use_16  land_use_17  \\\n",
              "0            0.000000          0.0          0.0     0.007874          0.0   \n",
              "1            0.000406          0.0          0.0     0.000000          0.0   \n",
              "\n",
              "land_use  land_use_18  land_use_19  land_use_20  land_use_21  land_use_22  \n",
              "0            0.000000          0.0     0.001923     0.008865          0.0  \n",
              "1            0.004196          0.0     0.070251     0.000000          0.0  \n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load land use data and reduce data types\n",
        "hexagons_with_land_use_df = pd.read_parquet(HEXAGONS_WITH_LAND_USE_PATH)\n",
        "hexagons_with_land_use_df = hexagons_with_land_use_df.astype(np.float16)\n",
        "hexagons_with_land_use_df = hexagons_with_land_use_df.reset_index()\n",
        "hexagons_with_land_use_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_land_use_data(df: pd.DataFrame, on=\"hex_id\", suffix: str = None) -> pd.DataFrame:\n",
        "\tdf = pd.merge(\n",
        "\t\tdf,\n",
        "\t\thexagons_with_land_use_df.add_suffix(suffix) if suffix else hexagons_with_land_use_df,\n",
        "\t\tleft_on=on,\n",
        "\t\tright_on=f\"hexagon_id{suffix}\" if suffix else \"hexagon_id\",\n",
        "\t)\n",
        "\treturn df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add land use data as feature of the start location\n",
        "trips_orig = add_land_use_data(trips_orig)\n",
        "trips_orig_dest = add_land_use_data(trips_orig_dest, on=\"start_hex_id\", suffix=\"_start\")\n",
        "trips_orig_dest = add_land_use_data(trips_orig_dest, on=\"end_hex_id\", suffix=\"_end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['datetime', 'start_hex_id', 'end_hex_id', 'demand', 'h3_res',\n",
              "       'time_interval_length', 'min_temperature', 'max_temperature',\n",
              "       'mean_temperature', 'mean_mean_wind_speed', 'mean_total_cloud_cover',\n",
              "       'sum_precipitation', 'hex_start', 'sustenance_poi_start',\n",
              "       'public_transport_poi_start', 'education_poi_start',\n",
              "       'arts_and_culture_poi_start', 'sports_poi_start', 'hex_end',\n",
              "       'sustenance_poi_end', 'public_transport_poi_end', 'education_poi_end',\n",
              "       'arts_and_culture_poi_end', 'sports_poi_end', 'hexagon_id_start',\n",
              "       'land_use_1_start', 'land_use_2_start', 'land_use_3_start',\n",
              "       'land_use_4_start', 'land_use_5_start', 'land_use_6_start',\n",
              "       'land_use_7_start', 'land_use_8_start', 'land_use_9_start',\n",
              "       'land_use_10_start', 'land_use_11_start', 'land_use_12_start',\n",
              "       'land_use_13_start', 'land_use_14_start', 'land_use_15_start',\n",
              "       'land_use_16_start', 'land_use_17_start', 'land_use_18_start',\n",
              "       'land_use_19_start', 'land_use_20_start', 'land_use_21_start',\n",
              "       'land_use_22_start', 'hexagon_id_end', 'land_use_1_end',\n",
              "       'land_use_2_end', 'land_use_3_end', 'land_use_4_end', 'land_use_5_end',\n",
              "       'land_use_6_end', 'land_use_7_end', 'land_use_8_end', 'land_use_9_end',\n",
              "       'land_use_10_end', 'land_use_11_end', 'land_use_12_end',\n",
              "       'land_use_13_end', 'land_use_14_end', 'land_use_15_end',\n",
              "       'land_use_16_end', 'land_use_17_end', 'land_use_18_end',\n",
              "       'land_use_19_end', 'land_use_20_end', 'land_use_21_end',\n",
              "       'land_use_22_end'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trips_orig_dest.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "del hexagons_with_land_use_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory usage: 4022.4545879364014 MB\n",
            "memory usage: 516.5524291992188 MB\n",
            "memory usage: 2962.0358276367188 MB\n"
          ]
        }
      ],
      "source": [
        "print(f\"memory usage: {trips_orig.memory_usage(index=True, deep=True).sum() / 1024**2} MB\")\n",
        "print(f\"memory usage: {trips_orig_dest.memory_usage(index=True, deep=True).sum() / 1024**2} MB\")\n",
        "print(f\"memory usage: {availability_df.memory_usage(index=True, deep=True).sum() / 1024**2} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "hex_id_map = dict(\n",
        "    enumerate(\n",
        "        np.unique(\n",
        "            np.concatenate(\n",
        "                [\n",
        "                    trips_orig.hex_id.unique(),\n",
        "                    trips_orig_dest.start_hex_id.unique(),\n",
        "                    trips_orig_dest.end_hex_id.unique(),\n",
        "                    availability_df.hex_id.unique(),\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "    )\n",
        ")\n",
        "hex_id_map = {v: k for k, v in hex_id_map.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remap_hex_ids(df: pd.DataFrame, on=\"hex_id\") -> pd.DataFrame:\n",
        "\tdf[\"hex_id\"] = df[\"hex_id\"].map(hex_id_map)\n",
        "\treturn df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig[\"hex_id\"] = trips_orig[\"hex_id\"].map(hex_id_map)\n",
        "\n",
        "trips_orig_dest[\"start_hex_id\"] = trips_orig_dest[\"start_hex_id\"].map(hex_id_map)\n",
        "trips_orig_dest[\"end_hex_id\"] = trips_orig_dest[\"end_hex_id\"].map(hex_id_map)\n",
        "\n",
        "availability_df[\"hex_id\"] = availability_df[\"hex_id\"].map(hex_id_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory usage: 3222.9605083465576 MB\n",
            "memory usage: 404.86541748046875 MB\n",
            "memory usage: 2041.7916870117188 MB\n"
          ]
        }
      ],
      "source": [
        "print(f\"memory usage: {trips_orig.memory_usage(index=True, deep=True).sum() / 1024**2} MB\")\n",
        "print(f\"memory usage: {trips_orig_dest.memory_usage(index=True, deep=True).sum() / 1024**2} MB\")\n",
        "print(f\"memory usage: {availability_df.memory_usage(index=True, deep=True).sum() / 1024**2} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig.to_feather(MODEL_DATA_PATH)\n",
        "trips_orig_dest.to_feather(REDUCED_MODEL_DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_time_features_to_model_data(model_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    # add time features\n",
        "    model_data['hour'] = model_data.datetime.dt.hour\n",
        "    model_data['weekday'] = model_data.datetime.dt.weekday\n",
        "    model_data['month'] = model_data.datetime.dt.month\n",
        "\n",
        "    # convert time features to dummy variables (one-hot encoding) and replace the original features\n",
        "    hour_dummies = pd.get_dummies(model_data['hour']).add_prefix('hour_')\n",
        "    weekday_dummies = pd.get_dummies(model_data['weekday']).add_prefix('weekday_')\n",
        "    month_dummies = pd.get_dummies(model_data['month']).add_prefix('month_')\n",
        "\n",
        "    model_data.drop(['hour', 'weekday', 'month'], axis=1, inplace=True)\n",
        "    model_data = pd.concat([model_data, hour_dummies, weekday_dummies, month_dummies], axis=1)\n",
        "\n",
        "    del hour_dummies, weekday_dummies, month_dummies\n",
        "    # remove datetime_start_floored column as it won't be needed anymore\n",
        "\n",
        "    model_data = model_data.drop(columns=['datetime'])\n",
        "    return model_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_invalid_cols(df : pd.DataFrame):\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    cols = df.select_dtypes(include=np.number).sum().apply(lambda x: np.isinf(x))\n",
        "    warnings.filterwarnings(\"default\")\n",
        "    return cols[cols].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_invalid_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    invalid_cols = get_invalid_cols(df)\n",
        "\n",
        "    # check if sum of all values in each column can be represented by the dtype of the column\n",
        "    # if this is not the case we cannot scale the data as calculated the mean will return erroneous values\n",
        "    if len(invalid_cols) > 0:\n",
        "        for col in invalid_cols:\n",
        "            if df[col].dtype != np.float16:\n",
        "                raise ValueError(\n",
        "                    \"Unexpected dtype for column {}. Expected float16, got {}\".format(\n",
        "                        col, df[col].dtype\n",
        "                    )\n",
        "                )\n",
        "            df[col] = df[col].astype(np.float32)\n",
        "\n",
        "    invalid_cols = get_invalid_cols(df)\n",
        "    if len(invalid_cols) > 0:\n",
        "        raise ValueError(\"Invalid columns remaining\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_temperature_features(model_data: pd.DataFrame, t: int) -> pd.DataFrame:\n",
        "    if t > 5:\n",
        "        return model_data.drop(columns=[\"mean_temperature\"])\n",
        "    return model_data.drop(columns=[\"min_temperature\", \"max_temperature\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d44b40d6b2d42b5a1c1e14f33f1e7e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if not os.path.exists(MODEL_DATA_DIR_PATH):\n",
        "    os.makedirs(MODEL_DATA_DIR_PATH)\n",
        "\n",
        "# store model data for each time and hex resolution in one file\n",
        "# additionally create dummies for start and end hexagons\n",
        "for h3_res, t, df_name in tqdm(\n",
        "    list(\n",
        "        itertools.product(\n",
        "            CALC_H3_RESOLUTIONS,\n",
        "            CALC_TIME_INTERVAL_LENGTHS,\n",
        "            [\"demand\", \"availability\"],\n",
        "        )\n",
        "    )\n",
        "):\n",
        "    model_data = trips_orig if df_name == \"demand\" else availability_df\n",
        "\n",
        "    model_data = model_data[\n",
        "        (model_data.h3_res == h3_res) & (model_data.time_interval_length == t)\n",
        "    ].reset_index(drop=True)\n",
        "\n",
        "    model_data = choose_temperature_features(model_data, t)\n",
        "\n",
        "    model_data = add_time_features_to_model_data(model_data)\n",
        "\n",
        "    hex_dummies = pd.get_dummies(model_data.hex_id, prefix=\"start_\")\n",
        "    model_data = pd.concat([model_data, hex_dummies], axis=1)\n",
        "    model_data = model_data.drop(columns=[\"hex_id\", \"h3_res\", \"time_interval_length\"])\n",
        "\n",
        "    model_data = fix_invalid_cols(model_data)\n",
        "\n",
        "    model_data.to_feather(\n",
        "        os.path.join(MODEL_DATA_DIR_PATH, f\"{df_name}_{h3_res}_{t}.feather\")\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "trips_orig_dest = choose_temperature_features(\n",
        "    trips_orig_dest, ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH\n",
        ")\n",
        "\n",
        "trips_orig_dest = add_time_features_to_model_data(\n",
        "    trips_orig_dest\n",
        ")\n",
        "\n",
        "start_hex_dummies = pd.get_dummies(\n",
        "    trips_orig_dest.start_hex_id, prefix=\"start_\"\n",
        ")\n",
        "end_hex_dummies = pd.get_dummies(trips_orig_dest.end_hex_id, prefix=\"end_\")\n",
        "trips_orig_dest = pd.concat(\n",
        "    [trips_orig_dest, start_hex_dummies, end_hex_dummies], axis=1\n",
        ")\n",
        "trips_orig_dest = trips_orig_dest.drop(\n",
        "    columns=[\"start_hex_id\", \"end_hex_id\", \"h3_res\", \"time_interval_length\"]\n",
        ")\n",
        "\n",
        "trips_orig_dest = fix_invalid_cols(trips_orig_dest)\n",
        "\n",
        "trips_orig_dest.to_feather(\n",
        "    os.path.join(\n",
        "        MODEL_DATA_DIR_PATH,\n",
        "        f\"demand_orig_dest_{ORIGIN_DESTINATION_H3_RESOLUTION}_{ORIGIN_DESTINATION_TIME_INTERVAL_LENGTH}.feather\",\n",
        "    )\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('AAA_MAGMA')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6f128d9a36ac5782f4755de02247e2ed06e0bf1d935493c1f1cb8e21863a0d39"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
