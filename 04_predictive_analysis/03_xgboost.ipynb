{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import distributions\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moritz/miniconda3/envs/AAA_MAGMA_2/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.config import *\n",
    "from modules.storage import get_demand_model_data, store_results, get_results_df, get_demand_orig_dest_model_data, get_availability_model_data\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from modules.xgboost import perform_randomized_grid_search, get_best_hyperparameters, model_already_evaluated, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Training\n",
    "In this notebook, we will train XGBoost as an additional model. The reason we decided to put in this extra effort is, because we recently learned about XGBoost and recognized the large bicycle sharing dataset as a perfect fit for it.  \n",
    "With the right hyperparameters XGBoost is extremely scalable to large datasets.\n",
    "E.g. we decided to use `hist` as the method for building the trees. This means during the tree building process, the algorithm will not try every possible split but only some at certain quantiles. This approach is known as the (weighted) quantile sktech. Also it uses an approximation of the real histograms to determine the quantiles, wich is even faster.  \n",
    "\n",
    "To find the best hyperparameters, we perform a randomized hyperparameter grid search based on successive halving. This approach is an enhanced version of the successive halving algorithm we used for SVMs.\n",
    "Instead of trying out hyperparameters specified by the explicit hyperparameter grid, the algorithm tries out a random subset.\n",
    "Randomized search has multiple advantages compared to grid search.\n",
    "Firstly, distributions instead of discrete values can be defined. Secondly, the number of hyperparameters to be tested can be easily altered. Thirdly, randomized searches are more efficient that grid searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {\n",
    "    \"eta\": distributions.uniform(0, 0.3),\n",
    "    \"gamma\": distributions.uniform(0, 5),\n",
    "    \"max_depth\": distributions.randint(1, 10),\n",
    "    \"lambda\": distributions.expon(),\n",
    "    \"booster\": [\"gbtree\"],\n",
    "    \"tree_method\": [\"hist\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already performed grid search for demand\n",
      "Already performed grid search for availability\n"
     ]
    }
   ],
   "source": [
    "for outcome in ['demand', 'availability']:\n",
    "\tresult_path = XGBOOST_FIRST_STAGE_DEMAND_RESULTS_PATH if outcome == 'demand' else XGBOOST_FIRST_STAGE_AVAILABILITY_RESULTS_PATH\n",
    "\tif not get_results_df(result_path).empty:\n",
    "\t\tprint(f\"Already performed grid search for {outcome}\")\n",
    "\t\tcontinue\n",
    "\tres = perform_randomized_grid_search(\n",
    "\t\tget_demand_model_data if outcome == 'demand' else get_availability_model_data,\n",
    "\t\thyperparameter_grid,\n",
    "\t\tTUNE_H3_RESOLUTION,\n",
    "\t\tTUNE_TIME_INTERVAL_LENGTH,\n",
    "\t)\n",
    "\tstore_results(res, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>n_resources</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_booster</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_lambda</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>6</td>\n",
       "      <td>153819</td>\n",
       "      <td>1.253628</td>\n",
       "      <td>0.080693</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.081692</td>\n",
       "      <td>0.091953</td>\n",
       "      <td>2.456889</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.050668</td>\n",
       "      <td>0.884757</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.670141</td>\n",
       "      <td>-11.501171</td>\n",
       "      <td>-11.378437</td>\n",
       "      <td>-11.860564</td>\n",
       "      <td>-11.539376</td>\n",
       "      <td>-11.589938</td>\n",
       "      <td>0.164219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>6</td>\n",
       "      <td>153819</td>\n",
       "      <td>1.103867</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.154679</td>\n",
       "      <td>2.444233</td>\n",
       "      <td>1.099205</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.626666</td>\n",
       "      <td>1.055941</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.466102</td>\n",
       "      <td>-12.301324</td>\n",
       "      <td>-12.230210</td>\n",
       "      <td>-12.669970</td>\n",
       "      <td>-12.158934</td>\n",
       "      <td>-12.365308</td>\n",
       "      <td>0.183256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>5</td>\n",
       "      <td>51273</td>\n",
       "      <td>0.517885</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.081692</td>\n",
       "      <td>0.091953</td>\n",
       "      <td>2.456889</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.680344</td>\n",
       "      <td>1.518570</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.037725</td>\n",
       "      <td>-9.629830</td>\n",
       "      <td>-9.737628</td>\n",
       "      <td>-11.334504</td>\n",
       "      <td>-10.079148</td>\n",
       "      <td>-10.163767</td>\n",
       "      <td>0.609976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>5</td>\n",
       "      <td>51273</td>\n",
       "      <td>0.444084</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.154679</td>\n",
       "      <td>2.444233</td>\n",
       "      <td>1.099205</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.329992</td>\n",
       "      <td>1.709187</td>\n",
       "      <td>4</td>\n",
       "      <td>-10.827068</td>\n",
       "      <td>-10.849388</td>\n",
       "      <td>-10.944522</td>\n",
       "      <td>-12.151200</td>\n",
       "      <td>-11.144852</td>\n",
       "      <td>-11.183406</td>\n",
       "      <td>0.496734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>5</td>\n",
       "      <td>51273</td>\n",
       "      <td>0.452911</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.089171</td>\n",
       "      <td>1.499596</td>\n",
       "      <td>1.359431</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.046733</td>\n",
       "      <td>1.793300</td>\n",
       "      <td>5</td>\n",
       "      <td>-12.580637</td>\n",
       "      <td>-11.961383</td>\n",
       "      <td>-12.302119</td>\n",
       "      <td>-13.817094</td>\n",
       "      <td>-12.433894</td>\n",
       "      <td>-12.619026</td>\n",
       "      <td>0.633094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.061079</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>3.370100</td>\n",
       "      <td>0.053228</td>\n",
       "      <td>...</td>\n",
       "      <td>-223.201994</td>\n",
       "      <td>266.234970</td>\n",
       "      <td>1500</td>\n",
       "      <td>-39.781105</td>\n",
       "      <td>-28.049236</td>\n",
       "      <td>-38.738112</td>\n",
       "      <td>-46.206308</td>\n",
       "      <td>-46.596891</td>\n",
       "      <td>-39.874330</td>\n",
       "      <td>6.729328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.079253</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.220810</td>\n",
       "      <td>0.418220</td>\n",
       "      <td>...</td>\n",
       "      <td>-224.152720</td>\n",
       "      <td>265.603102</td>\n",
       "      <td>1501</td>\n",
       "      <td>-57.190265</td>\n",
       "      <td>-37.842771</td>\n",
       "      <td>-55.060084</td>\n",
       "      <td>-64.433728</td>\n",
       "      <td>-65.389961</td>\n",
       "      <td>-55.983362</td>\n",
       "      <td>9.912446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.085730</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.263419</td>\n",
       "      <td>0.092711</td>\n",
       "      <td>...</td>\n",
       "      <td>-227.299311</td>\n",
       "      <td>281.665833</td>\n",
       "      <td>1502</td>\n",
       "      <td>-37.602344</td>\n",
       "      <td>-24.917929</td>\n",
       "      <td>-36.082163</td>\n",
       "      <td>-43.316048</td>\n",
       "      <td>-43.819009</td>\n",
       "      <td>-37.147499</td>\n",
       "      <td>6.833217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.093715</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>4.099735</td>\n",
       "      <td>0.259581</td>\n",
       "      <td>...</td>\n",
       "      <td>-227.774339</td>\n",
       "      <td>280.359382</td>\n",
       "      <td>1503</td>\n",
       "      <td>-48.908906</td>\n",
       "      <td>-32.567209</td>\n",
       "      <td>-47.245316</td>\n",
       "      <td>-55.258048</td>\n",
       "      <td>-56.230843</td>\n",
       "      <td>-48.042064</td>\n",
       "      <td>8.485092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.077724</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.082829</td>\n",
       "      <td>0.739212</td>\n",
       "      <td>...</td>\n",
       "      <td>-237.802184</td>\n",
       "      <td>282.286214</td>\n",
       "      <td>1504</td>\n",
       "      <td>-63.908426</td>\n",
       "      <td>-41.838422</td>\n",
       "      <td>-60.854841</td>\n",
       "      <td>-71.690363</td>\n",
       "      <td>-72.559827</td>\n",
       "      <td>-62.170376</td>\n",
       "      <td>11.105950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iter  n_resources  mean_fit_time  std_fit_time  mean_score_time  \\\n",
       "1503     6       153819       1.253628      0.080693         0.021332   \n",
       "1502     6       153819       1.103867      0.031088         0.018577   \n",
       "1500     5        51273       0.517885      0.015503         0.009318   \n",
       "1501     5        51273       0.444084      0.012859         0.008346   \n",
       "1499     5        51273       0.452911      0.012183         0.009282   \n",
       "...    ...          ...            ...           ...              ...   \n",
       "774      0          211       0.061079      0.009042         0.004153   \n",
       "652      0          211       0.079253      0.002553         0.004052   \n",
       "267      0          211       0.085730      0.010827         0.004940   \n",
       "295      0          211       0.093715      0.006574         0.004455   \n",
       "747      0          211       0.077724      0.006479         0.004124   \n",
       "\n",
       "      std_score_time param_booster  param_eta  param_gamma  param_lambda  ...  \\\n",
       "1503        0.002862        gbtree   0.081692     0.091953      2.456889  ...   \n",
       "1502        0.000411        gbtree   0.154679     2.444233      1.099205  ...   \n",
       "1500        0.001029        gbtree   0.081692     0.091953      2.456889  ...   \n",
       "1501        0.000331        gbtree   0.154679     2.444233      1.099205  ...   \n",
       "1499        0.001599        gbtree   0.089171     1.499596      1.359431  ...   \n",
       "...              ...           ...        ...          ...           ...  ...   \n",
       "774         0.000214        gbtree   0.003647     3.370100      0.053228  ...   \n",
       "652         0.000170        gbtree   0.000695     0.220810      0.418220  ...   \n",
       "267         0.001609        gbtree   0.002846     0.263419      0.092711  ...   \n",
       "295         0.000359        gbtree   0.001544     4.099735      0.259581  ...   \n",
       "747         0.000333        gbtree   0.000003     2.082829      0.739212  ...   \n",
       "\n",
       "      mean_test_score std_test_score rank_test_score  split0_train_score  \\\n",
       "1503       -13.050668       0.884757               1          -11.670141   \n",
       "1502       -13.626666       1.055941               2          -12.466102   \n",
       "1500       -14.680344       1.518570               3          -10.037725   \n",
       "1501       -15.329992       1.709187               4          -10.827068   \n",
       "1499       -16.046733       1.793300               5          -12.580637   \n",
       "...               ...            ...             ...                 ...   \n",
       "774       -223.201994     266.234970            1500          -39.781105   \n",
       "652       -224.152720     265.603102            1501          -57.190265   \n",
       "267       -227.299311     281.665833            1502          -37.602344   \n",
       "295       -227.774339     280.359382            1503          -48.908906   \n",
       "747       -237.802184     282.286214            1504          -63.908426   \n",
       "\n",
       "      split1_train_score  split2_train_score  split3_train_score  \\\n",
       "1503          -11.501171          -11.378437          -11.860564   \n",
       "1502          -12.301324          -12.230210          -12.669970   \n",
       "1500           -9.629830           -9.737628          -11.334504   \n",
       "1501          -10.849388          -10.944522          -12.151200   \n",
       "1499          -11.961383          -12.302119          -13.817094   \n",
       "...                  ...                 ...                 ...   \n",
       "774           -28.049236          -38.738112          -46.206308   \n",
       "652           -37.842771          -55.060084          -64.433728   \n",
       "267           -24.917929          -36.082163          -43.316048   \n",
       "295           -32.567209          -47.245316          -55.258048   \n",
       "747           -41.838422          -60.854841          -71.690363   \n",
       "\n",
       "      split4_train_score  mean_train_score  std_train_score  \n",
       "1503          -11.539376        -11.589938         0.164219  \n",
       "1502          -12.158934        -12.365308         0.183256  \n",
       "1500          -10.079148        -10.163767         0.609976  \n",
       "1501          -11.144852        -11.183406         0.496734  \n",
       "1499          -12.433894        -12.619026         0.633094  \n",
       "...                  ...               ...              ...  \n",
       "774           -46.596891        -39.874330         6.729328  \n",
       "652           -65.389961        -55.983362         9.912446  \n",
       "267           -43.819009        -37.147499         6.833217  \n",
       "295           -56.230843        -48.042064         8.485092  \n",
       "747           -72.559827        -62.170376        11.105950  \n",
       "\n",
       "[1504 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_results_df(XGBOOST_FIRST_STAGE_DEMAND_RESULTS_PATH)\n",
    "res.sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = list(\n",
    "\titertools.product(\n",
    "\t\tPREDICTIVE_H3_RESOLUTIONS,\n",
    "\t\tCALC_TIME_INTERVAL_LENGTHS,\n",
    "\t)\n",
    ")+ ADDITIONAL_PREDICTIVE_RESOLUTIONS\n",
    "iterator = list(itertools.product(\n",
    "\tresolutions,\n",
    "\t['demand', 'availability'],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training For All Resolutions\n",
    "Now where we found a good set of hyperparameters, we can train the model for all resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0170d6703ea64aaf8f306a50812c1105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demand       - 7 - 1 already done\n",
      "availability - 7 - 1 already done\n",
      "demand       - 7 - 2 already done\n",
      "availability - 7 - 2 already done\n",
      "demand       - 7 - 6 already done\n",
      "availability - 7 - 6 already done\n",
      "demand       - 7 - 24 already done\n",
      "availability - 7 - 24 already done\n",
      "demand       - 8 - 1 already done\n",
      "availability - 8 - 1 already done\n",
      "demand       - 8 - 2 already done\n",
      "availability - 8 - 2 already done\n",
      "demand       - 8 - 6 already done\n",
      "availability - 8 - 6 already done\n",
      "demand       - 8 - 24 already done\n",
      "availability - 8 - 24 already done\n",
      "demand       - 9 - 24 already done\n",
      "availability - 9 - 24 already done\n"
     ]
    }
   ],
   "source": [
    "for (h3_res, time_interval_length), outcome in tqdm(iterator):\n",
    "    padded_outcome = \"availability\" if outcome == \"availability\" else \"demand      \"\n",
    "    print_output = f\"{padded_outcome} - {h3_res} - {time_interval_length}\"\n",
    "    tqdm.write(print_output + \" started\", end=\"\\r\")\n",
    "\n",
    "    result_path, first_stage_result_path = (\n",
    "        (\n",
    "            XGBOOST_SECOND_STAGE_DEMAND_RESULTS_PATH,\n",
    "            XGBOOST_FIRST_STAGE_DEMAND_RESULTS_PATH,\n",
    "        )\n",
    "        if outcome == \"demand\"\n",
    "        else (\n",
    "            XGBOOST_SECOND_STAGE_AVAILABILITY_RESULTS_PATH,\n",
    "            XGBOOST_FIRST_STAGE_AVAILABILITY_RESULTS_PATH,\n",
    "        )\n",
    "    )\n",
    "    if model_already_evaluated(result_path, h3_res, time_interval_length):\n",
    "        tqdm.write(print_output + \" already done\")\n",
    "        continue\n",
    "    hyperparameters = get_best_hyperparameters(get_results_df(first_stage_result_path))\n",
    "    start = time.time()\n",
    "    res = evaluate(\n",
    "        get_demand_model_data,\n",
    "        hyperparameters,\n",
    "        h3_res,\n",
    "        time_interval_length,\n",
    "    )\n",
    "    duration = time.time() - start\n",
    "    res = pd.DataFrame(res, index=[0])\n",
    "    res[\"h3_res\"] = h3_res\n",
    "    res[\"time_interval_length\"] = time_interval_length\n",
    "    res[\"train_duration\"] = duration\n",
    "\n",
    "    store_results(res, result_path)\n",
    "    tqdm.write(print_output + \" done    \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to SVMs and Neural Networks, we also train one additional model for origin-destination pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(XGBOOST_SECOND_STAGE_DEMAND_RESULTS_PATH)\n",
    "if results_df[results_df[\"h3_res\"] == int(f\"{ORIGIN_DESTINATION_H3_RESOLUTION}{ORIGIN_DESTINATION_H3_RESOLUTION}\")].empty:\n",
    "\thyperparameters = get_best_hyperparameters(get_results_df(XGBOOST_FIRST_STAGE_DEMAND_RESULTS_PATH))\n",
    "\tstart = time.time()\n",
    "\tres = evaluate(\n",
    "\t\tlambda _, __: get_demand_orig_dest_model_data(),\n",
    "\t\thyperparameters,\n",
    "\t\tORIGIN_DESTINATION_H3_RESOLUTION,\n",
    "\t\tORIGIN_DESTINATION_H3_RESOLUTION,\n",
    "\t)\n",
    "\tduration = time.time() - start\n",
    "\tres = pd.DataFrame(res, index=[0])\n",
    "\tres[\"h3_res\"] = int(f\"{ORIGIN_DESTINATION_H3_RESOLUTION}{ORIGIN_DESTINATION_H3_RESOLUTION}\")\n",
    "\tres[\"time_interval_length\"] = time_interval_length\n",
    "\tres[\"train_duration\"] = duration\n",
    "\tstore_results(res, XGBOOST_SECOND_STAGE_DEMAND_RESULTS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AAA_MAGMA_2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7d5aa3afc48e507e79aab9da179a989cdb2272ea84b7e2d3626efebcf2c71f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
