{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    HalvingGridSearchCV,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(path):\n",
    "    if os.path.isfile(path):\n",
    "        return pd.read_parquet(path)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def store_results(new_results, path):\n",
    "    if os.path.isfile(path):\n",
    "        results = pd.read_parquet(path)\n",
    "        results = pd.concat([results, new_results], ignore_index=True)\n",
    "        results.to_parquet(path)\n",
    "    else:\n",
    "        new_results.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method will get model data for a specific h3 resolution and time interval length\n",
    "def get_model_data(h3_res, time_interval_length):\n",
    "    model_data = pd.read_feather(os.path.join(MODEL_DATA_DIR_PATH, f\"{h3_res}_{time_interval_length}.feather\"))\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale_data(model_data):\n",
    "    y = model_data[\"demand\"]\n",
    "    X = model_data.drop(columns=[\"demand\"])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(param_grid, X_train, y_train):\n",
    "    svr = SVR()\n",
    "    models = HalvingGridSearchCV(svr, param_grid, n_jobs=-1, scoring=\"neg_mean_squared_error\", random_state=42)\n",
    "    # print(X_train)\n",
    "    models.fit(X_train, y_train)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_percentage_error(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred) / y_true.mean()\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5\n",
    "\n",
    "\n",
    "def get_results(models, h3_res, time_interval_length, do_evaluate_model, X_test, y_test):\n",
    "    results = pd.DataFrame(models.cv_results_)\n",
    "    results['n_iter'] = 0\n",
    "    results.loc[0, 'n_iter'] = models.best_estimator_.n_iter_\n",
    "    results['h3_res'] = h3_res\n",
    "    results['time_interval_length'] = time_interval_length\n",
    "\n",
    "    if do_evaluate_model:\n",
    "        y_pred = models.best_estimator_.predict(X_test)\n",
    "        results['mse'] = mean_squared_error(y_test, y_pred)\n",
    "        results['mae'] = mean_absolute_error(y_test, y_pred)\n",
    "        results['mape'] = mean_average_percentage_error(y_test, y_pred)\n",
    "        results['rmse'] = root_mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_metas():\n",
    "    return [\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100], 'gamma': [-1],            'degree': [-1],         'max_iter': [100000]},\n",
    "        {'kernel': ['rbf'],    'C': [1, 10, 100], 'gamma': [0.001, 0.0001], 'degree': [-1],         'max_iter': [100000]},\n",
    "        {'kernel': ['poly'],   'C': [1, 10, 100], 'gamma': [-1],            'degree': [2, 3, 4, 5], 'max_iter': [100000]}\n",
    "    ]\n",
    "\n",
    "\n",
    "def check_if_model_result_empty(meta, results, h3_res, time_interval_length):\n",
    "    return results[\n",
    "        (results['h3_res'] == h3_res) &\n",
    "        (results['time_interval_length'] == time_interval_length) &\n",
    "        (results['param_kernel'] == meta[0]) &\n",
    "        (results['param_C'] == meta[1]) &\n",
    "        ((results['param_gamma'] == meta[2]) | (pd.isnull(results['param_gamma']))) &\n",
    "        ((results['param_degree'] == meta[3]) | (pd.isnull(results['param_degree']))) \n",
    "    ]['mean_test_score'].empty\n",
    "\n",
    "\n",
    "def get_param_grid(model_meta):\n",
    "    param_grid = {\n",
    "        'kernel': [model_meta[0]],\n",
    "        'C': [model_meta[1]],\n",
    "        'max_iter': [model_meta[4]]\n",
    "    }\n",
    "    if model_meta[2] > 0: param_grid = {**param_grid, 'gamma': [model_meta[2]]}\n",
    "    if model_meta[3] > 0: param_grid = {**param_grid, 'degree': [model_meta[3]]}\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_availabe_models_metas_first_stage(h3_res, time_interval_length):\n",
    "    results = get_results_df(SVM_FIRST_STAGE_RESULTS_PATH)    \n",
    "    all_metas = get_svm_metas()\n",
    "\n",
    "    # the following code will create all possible combinations of parameters for all models\n",
    "    metas = [list(product(*meta.values())) for meta in all_metas]\n",
    "    metas = [item for sublist in metas for item in sublist]\n",
    "    available_metas = metas\n",
    "    if not results.empty:\n",
    "        available_metas = [meta for meta in metas if check_if_model_result_empty(meta, results, h3_res, time_interval_length)]\n",
    "\n",
    "    # group_by h3 and time, put other params in param grid\n",
    "    metas_grouped = []\n",
    "    for kernel in ['linear', 'rbf', 'poly']:\n",
    "        param_grid = [get_param_grid(meta) for meta in available_metas if (meta[0] == kernel)]\n",
    "        if len(param_grid) == 0: continue\n",
    "        metas_grouped.append(param_grid)\n",
    "\n",
    "    return metas_grouped\n",
    "\n",
    "def get_availabe_models_metas_second_stage(h3_res, time_interval_length):\n",
    "    results = get_results_df(SVM_FIRST_STAGE_RESULTS_PATH)    \n",
    "    best_model = results.sort_values(by=['mean_train_score'], ascending=False)\n",
    "    meta = [\n",
    "        h3_res,\n",
    "        time_interval_length,\n",
    "        best_model['param_kernel'].iloc[0],\n",
    "        best_model['param_C'].iloc[0],\n",
    "        best_model['param_gamma'].iloc[0],\n",
    "        best_model['param_degree'].iloc[0]\n",
    "    ]\n",
    "    \n",
    "    if ((not results.empty) & (check_if_model_result_empty(meta, results, h3_res, time_interval_length))):\n",
    "        return [[{\n",
    "            'kernel': [best_model['param_kernel'].iloc[0]],\n",
    "            'C': [best_model['param_C'].iloc[0]],\n",
    "            'gamma': [best_model['param_gamma'].iloc[0]],\n",
    "            'degree': [best_model['param_degree'].iloc[0]],\n",
    "            'max_iter': [best_model['param_max_iter'].iloc[0]]\n",
    "        }]]\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_stage(path, h3_res, time_interval_length, get_metas_func, do_evaluate_model):\n",
    "    metas = get_metas_func(h3_res, time_interval_length)\n",
    "    \n",
    "    for param_grid in tqdm(metas):\n",
    "        feedback = f\"h3: {h3_res} | t:{time_interval_length} | - \" + param_grid[0][\"kernel\"][0]\n",
    "        tqdm.write(feedback, end=\"\\r\")\n",
    "        \n",
    "        model_data = get_model_data(h3_res, time_interval_length)\n",
    "        # print(model_data.isna().sum())\n",
    "        print(\"len of nan\")\n",
    "        print(len(model_data.columns[model_data.isna().any()]))\n",
    "        model_data = model_data.iloc[:1000] # to be deleted\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_and_scale_data(model_data)\n",
    "        models = train_model(param_grid, X_train, y_train)\n",
    "\n",
    "        results = get_results(models, h3_res, time_interval_length, do_evaluate_model, X_test, y_test)\n",
    "        store_results(results, path)  \n",
    "        tqdm.write(feedback + \" âœ“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6146640f82384591b8784156967ea3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execute_stage(SVM_FIRST_STAGE_RESULTS_PATH, TUNE_H3_RESOLUTION, TUNE_TIME_INTERVAL_LENGTH, get_availabe_models_metas_first_stage, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_parquet(SVM_FIRST_STAGE_RESULTS_PATH)\n",
    "# results.sort_values(by=['mean_train_score'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311b13fd55644f19b6ee25e64a33ca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of nan1 | - poly\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 269, in fit\n    raise ValueError(\nValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to bepreprocessed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\aaa-2022-magma\\04_predictive_analysis\\01_svm.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m h3_res \u001b[39min\u001b[39;00m PREDICTIVE_H3_RESOLUTIONS:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000009?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m time_interval_length \u001b[39min\u001b[39;00m CALC_TIME_INTERVAL_LENGTHS:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000009?line=2'>3</a>\u001b[0m         execute_stage(SVM_SECOND_STAGE_RESULTS_PATH, h3_res, time_interval_length, get_availabe_models_metas_second_stage, \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Dev\\aaa-2022-magma\\04_predictive_analysis\\01_svm.ipynb Cell 10'\u001b[0m in \u001b[0;36mexecute_stage\u001b[1;34m(path, h3_res, time_interval_length, get_metas_func, do_evaluate_model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000008?line=11'>12</a>\u001b[0m model_data \u001b[39m=\u001b[39m model_data\u001b[39m.\u001b[39miloc[:\u001b[39m1000\u001b[39m] \u001b[39m# to be deleted\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000008?line=13'>14</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m split_and_scale_data(model_data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000008?line=14'>15</a>\u001b[0m models \u001b[39m=\u001b[39m train_model(param_grid, X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000008?line=16'>17</a>\u001b[0m results \u001b[39m=\u001b[39m get_results(models, h3_res, time_interval_length, do_evaluate_model, X_test, y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000008?line=17'>18</a>\u001b[0m store_results(results, path)  \n",
      "\u001b[1;32mc:\\Dev\\aaa-2022-magma\\04_predictive_analysis\\01_svm.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(param_grid, X_train, y_train)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000005?line=2'>3</a>\u001b[0m models \u001b[39m=\u001b[39m HalvingGridSearchCV(svr, param_grid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39m# print(X_train)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000005?line=4'>5</a>\u001b[0m models\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/aaa-2022-magma/04_predictive_analysis/01_svm.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:261\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input_parameters(\n\u001b[0;32m    254\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m    255\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m    256\u001b[0m     groups\u001b[39m=\u001b[39mgroups,\n\u001b[0;32m    257\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_samples_orig \u001b[39m=\u001b[39m _num_samples(X)\n\u001b[1;32m--> 261\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y\u001b[39m=\u001b[39my, groups\u001b[39m=\u001b[39mgroups, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    263\u001b[0m \u001b[39m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_score_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_results_[\u001b[39m\"\u001b[39m\u001b[39mmean_test_score\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_index_]\n",
      "File \u001b[1;32mc:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py:366\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    359\u001b[0m     cv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checked_cv_orig\n\u001b[0;32m    361\u001b[0m more_results \u001b[39m=\u001b[39m {\n\u001b[0;32m    362\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m: [itr] \u001b[39m*\u001b[39m n_candidates,\n\u001b[0;32m    363\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_resources\u001b[39m\u001b[39m\"\u001b[39m: [n_resources] \u001b[39m*\u001b[39m n_candidates,\n\u001b[0;32m    364\u001b[0m }\n\u001b[1;32m--> 366\u001b[0m results \u001b[39m=\u001b[39m evaluate_candidates(\n\u001b[0;32m    367\u001b[0m     candidate_params, cv, more_results\u001b[39m=\u001b[39;49mmore_results\n\u001b[0;32m    368\u001b[0m )\n\u001b[0;32m    370\u001b[0m n_candidates_to_keep \u001b[39m=\u001b[39m ceil(n_candidates \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor)\n\u001b[0;32m    371\u001b[0m candidate_params \u001b[39m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[1;32mc:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[0;32m    854\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Dev\\miniconda\\envs\\AAA_MAGMA\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 269, in fit\n    raise ValueError(\nValueError: The dual coefficients or intercepts are not finite. The input data may contain large values and need to bepreprocessed.\n"
     ]
    }
   ],
   "source": [
    "for h3_res in PREDICTIVE_H3_RESOLUTIONS:\n",
    "    for time_interval_length in CALC_TIME_INTERVAL_LENGTHS:\n",
    "        execute_stage(SVM_SECOND_STAGE_RESULTS_PATH, h3_res, time_interval_length, get_availabe_models_metas_second_stage, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_parquet(SVM_SECOND_STAGE_RESULTS_PATH)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "480189c8b893ba0e665d676e4d8fbaa7064789f8cb0c8dbdf4a412ac1da4cf12"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('AAA_MAGMA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
