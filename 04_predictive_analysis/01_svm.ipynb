{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for model training\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# for evaluation & preprocessing\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    HalvingGridSearchCV,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "\n",
    "# for displaying results & feedback\n",
    "# from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather(MODEL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model will filter out correct h3 resolution and time interval\n",
    "# it will also one hot encode start and end hexagons and merge them to original dataframe\n",
    "def get_model_data(h3_res, time_interval_length):\n",
    "    model_data = data[(data['h3_res'] == h3_res) & (data['time_interval_length'] == time_interval_length)]\n",
    "    start_hex_dummies = pd.get_dummies(model_data.start_hex_id, prefix=\"start_\")\n",
    "    end_hex_dummies = pd.get_dummies(model_data.end_hex_id, prefix=\"end_\")\n",
    "    model_data = pd.concat([model_data, start_hex_dummies, end_hex_dummies], axis=1)\n",
    "    model_data = model_data.drop(columns=['start_hex_id', 'end_hex_id'])\n",
    "    return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model will filter out correct h3 resolution and time interval\n",
    "# it will also one hot encode start and end hexagons and merge them to original dataframe\n",
    "# def get_model_data(h3_res, time_interval_length):\n",
    "#     model_data = pd.read_feather(os.path.join(MODEL_DATA_DIR_PATH, f\"{h3_res}_{time_interval_length}.feather\"))\n",
    "#     return model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_scale_data(model_data):\n",
    "    y = model_data[\"demand\"]\n",
    "    X = model_data.drop(columns=[\"demand\"])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(param_grid, X_train, y_train):\n",
    "    svr = SVR()\n",
    "    clf = HalvingGridSearchCV(svr, param_grid, n_jobs=-1, scoring=\"neg_mean_squared_error\", random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_percentage_error(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred) / y_true.mean()\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_test, y_test):\n",
    "    results = pd.DataFrame(clf.cv_results_)\n",
    "    results.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_average_percentage_error(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    results['mse'] = 0\n",
    "    results['mae'] = 0\n",
    "    results['mape'] = 0\n",
    "    results['rmse'] = 0\n",
    "\n",
    "    results.loc[0, 'mse'] = mse\n",
    "    results.loc[0, 'mae'] = mae\n",
    "    results.loc[0, 'mape'] = mape\n",
    "    results.loc[0, 'rmse'] = rmse\n",
    "\n",
    "    # print(f\"MSE: {mse}\")\n",
    "    # print(f\"MAE: {mae}\")\n",
    "    # print(f\"MAPE: {mape}\")\n",
    "    # print(f\"RMSE: {rmse}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(path):\n",
    "    return os.path.isfile(path)\n",
    "\n",
    "\n",
    "def get_svm_results_columns():\n",
    "    return [\n",
    "        'h3_res',\n",
    "        'time_interval_length',\n",
    "        'mean_fit_time',\n",
    "        'std_fit_time',\n",
    "        'mean_score_time',\n",
    "        'std_score_time',\n",
    "        'param_C',\n",
    "        'param_kernel',\n",
    "        'param_gamma',\n",
    "        'param_degree',\n",
    "        'params',\n",
    "        'split0_test_score',\n",
    "        'split1_test_score',\n",
    "        'split2_test_score',\n",
    "        'split3_test_score',\n",
    "        'split4_test_score',\n",
    "        'mean_test_score',\n",
    "        'std_test_score',\n",
    "        'rank_test_score'\n",
    "    ]\n",
    "\n",
    "\n",
    "def init_results_df(path):\n",
    "    results = pd.DataFrame(columns=get_svm_results_columns())\n",
    "    results.to_parquet(path)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results_df(path):\n",
    "    if check_file_exists(path):\n",
    "        return pd.read_parquet(path)\n",
    "    return init_results_df(path)\n",
    "\n",
    "\n",
    "def get_svm_metas():\n",
    "    return [\n",
    "        {'kernel': ['linear'], 'C': [1, 10, 100], 'gamma': [-1], 'degree': [-1]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10, 100], 'gamma': [0.001, 0.0001], 'degree': [-1]},\n",
    "        {'kernel': ['poly'], 'C': [1, 10, 100], 'gamma': [-1], 'degree': [2, 3, 4, 5]}\n",
    "    ]\n",
    "\n",
    "\n",
    "def check_if_model_result_empty(meta, results):\n",
    "    return results[\n",
    "        (results['h3_res'] == meta[0]) &\n",
    "        (results['time_interval_length'] == meta[1]) &\n",
    "        (results['param_kernel'] == meta[2]) &\n",
    "        (results['param_C'] == meta[3]) &\n",
    "        ((results['param_gamma'] == meta[4]) | (pd.isnull(results['param_gamma']))) &\n",
    "        ((results['param_degree'] == meta[5]) | (pd.isnull(results['param_degree']))) \n",
    "    ]['mean_test_score'].empty\n",
    "\n",
    "\n",
    "def get_param_grid(model_meta):\n",
    "    param_grid = {\n",
    "        'kernel': [model_meta[2]],\n",
    "        'C': [model_meta[3]],\n",
    "    }\n",
    "    if model_meta[4] > 0:\n",
    "        param_grid = {**param_grid, 'gamma': [model_meta[4]]}\n",
    "    if model_meta[5] > 0:\n",
    "        param_grid = {**param_grid, 'degree': [model_meta[5]]}\n",
    "    \n",
    "    return param_grid\n",
    "\n",
    "\n",
    "def get_availabe_models_metas(path):\n",
    "    results = get_results_df(path)\n",
    "    all_metas = get_svm_metas()\n",
    "\n",
    "    # the following code will create all possible combinations of parameters for all models\n",
    "    metas = [list(product(*meta.values())) for meta in all_metas]\n",
    "    metas = [item for sublist in metas for item in sublist]\n",
    "    metas = list(product(PREDICTIVE_H3_RESOLUTIONS, CALC_TIME_INTERVAL_LENGTHS, metas)) \n",
    "    metas = [[item[0], item[1], *item[2]] for item in metas]\n",
    "\n",
    "    available_metas = metas\n",
    "    if not results.empty:\n",
    "        available_metas = [meta for meta in metas if check_if_model_result_empty(meta, results)]\n",
    "\n",
    "    # group_by h3 and time, put other params in param grid\n",
    "    metas_grouped = []\n",
    "    for h3_res in PREDICTIVE_H3_RESOLUTIONS:\n",
    "        for time_interval_length in CALC_TIME_INTERVAL_LENGTHS:\n",
    "            for kernel in ['linear', 'rbf', 'poly']:\n",
    "                param_grid = [get_param_grid(meta) for meta in available_metas if (meta[0] == h3_res and meta[1] == time_interval_length and meta[2] == kernel)]\n",
    "                if len(param_grid) == 0:\n",
    "                    continue\n",
    "                metas_grouped.append({\n",
    "                    'h3_res': h3_res,\n",
    "                    'time_interval_length': time_interval_length,\n",
    "                    'param_grid': param_grid\n",
    "                })\n",
    "\n",
    "    return metas_grouped\n",
    "\n",
    "def store_results(new_results, path):\n",
    "    results = pd.read_parquet(path)\n",
    "    results = pd.concat([results, new_results], ignore_index=True)\n",
    "    results.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2852e2019841bf9e0d771994b05d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h3: 7 | t:1 | - linear ✓\n",
      "h3: 7 | t:1 | - rbf ✓\n",
      "h3: 7 | t:1 | - poly ✓\n",
      "h3: 7 | t:2 | - linear ✓\n",
      "h3: 7 | t:2 | - rbf ✓\n",
      "h3: 7 | t:2 | - poly ✓\n",
      "h3: 7 | t:6 | - linear ✓\n",
      "h3: 7 | t:6 | - rbf ✓\n",
      "h3: 7 | t:6 | - poly ✓\n",
      "h3: 7 | t:24 | - linear ✓\n",
      "h3: 7 | t:24 | - rbf ✓\n",
      "h3: 7 | t:24 | - poly ✓\n",
      "h3: 8 | t:1 | - linear ✓\n",
      "h3: 8 | t:1 | - rbf ✓\n",
      "h3: 8 | t:1 | - poly ✓\n",
      "h3: 8 | t:2 | - linear ✓\n",
      "h3: 8 | t:2 | - rbf ✓\n",
      "h3: 8 | t:2 | - poly ✓\n",
      "h3: 8 | t:6 | - linear ✓\n",
      "h3: 8 | t:6 | - rbf ✓\n",
      "h3: 8 | t:6 | - poly ✓\n",
      "h3: 8 | t:24 | - linear ✓\n",
      "h3: 8 | t:24 | - rbf ✓\n",
      "h3: 8 | t:24 | - poly ✓\n"
     ]
    }
   ],
   "source": [
    "metas = get_availabe_models_metas(SVM_RESULTS_PATH)\n",
    "disk_read_time = 0\n",
    "for meta in tqdm(metas):\n",
    "    h3_res = meta['h3_res']\n",
    "    time_interval_length = meta['time_interval_length']\n",
    "    param_grid = meta['param_grid']\n",
    "    feedback = f\"h3: {h3_res} | t:{time_interval_length} | - \" + param_grid[0][\"kernel\"][0]\n",
    "    tqdm.write( feedback, end=\"\\r\")\n",
    "    start = time()\n",
    "    model_data = get_model_data(h3_res, time_interval_length)\n",
    "    disk_read_time += (time() - start)\n",
    "\n",
    "    # print(f\"Total data size: {len(model_data.index)}\")\n",
    "    model_data = model_data.iloc[:1000]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_and_scale_data(model_data)\n",
    "\n",
    "    # print(h3_res, time_interval_length)\n",
    "    # print(param_grid)\n",
    "    clf = train_model(param_grid, X_train, y_train)\n",
    "\n",
    "    results = evaluate_model(clf, X_test, y_test)\n",
    "    results['h3_res'] = h3_res\n",
    "    results['time_interval_length'] = time_interval_length\n",
    "    store_results(results, SVM_RESULTS_PATH)     \n",
    "    tqdm.write(feedback + \" ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.74320149421692\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(disk_read_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_parquet(SVM_RESULTS_PATH)\n",
    "# results.param_kernel.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f128d9a36ac5782f4755de02247e2ed06e0bf1d935493c1f1cb8e21863a0d39"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('AAA_MAGMA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
