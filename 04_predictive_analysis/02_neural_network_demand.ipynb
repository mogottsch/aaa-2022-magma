{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "\n",
        "sys.path.append(os.path.abspath('..'))\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from modules.config import *\n",
        "from modules.storage import get_results_df, get_demand_model_data, get_demand_orig_dest_model_data\n",
        "from modules.neural_network import execute_stage, get_first_stage_hyperparameters,get_second_stage_hyperparameters, get_third_stage_hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network Training\n",
        "In this notebook we train neural networks to predict demand. We first find the best subset of hyperparameters and then fit models with these hyperparameters in all resolutions.\n",
        "We use a multi-staged grid search, where we determine a set of best hyperparameters in one stage and then use it in the consecutive stages.\n",
        "While this approach will not guarantee to find the best hyperparameters, we expect it to be a good approximation, as a full scale grid search is computationally intractable.  \n",
        "\n",
        "To reduce training time, avoid overfitting and ensure that the model is sufficiently trained we use a high number of epochs and stop the model when the validation loss does not decrease any further.\n",
        "As we found that the validation loss changes in an unstable manner, we use a patience of 50 epochs.\n",
        "This means that Early Stopping will be activated after 50 epochs if the validation loss does not decrease any further.\n",
        "In addition we restore the weights of the epoch when the validation loss decreased last time.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_data(h3_res, time_interval_length):\n",
        "    model_data_train, model_data_test = get_demand_model_data(\n",
        "        h3_res, time_interval_length\n",
        "    )\n",
        "    return model_data_train, model_data_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the first stage, we find the best batch size by training simple single-layer Neural Networks, where the number of nodes is equal to the number of input features. The exact batch sizes, that we tried out, can be found in neural networks module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aebfafe602d545a2a5c610212acfc756",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:21:57] batch_size: 512 - nodes_per_feature: 1 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:57] batch_size: 256 - nodes_per_feature: 1 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:57] batch_size: 128 - nodes_per_feature: 1 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:57] batch_size: 64 - nodes_per_feature: 1 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:57] batch_size: 32 - nodes_per_feature: 1 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n"
          ]
        }
      ],
      "source": [
        "execute_stage(\n",
        "    get_model_data,\n",
        "    NN_FIRST_STAGE_DEMAND_RESULTS_PATH,\n",
        "    get_first_stage_hyperparameters,\n",
        "    TUNE_H3_RESOLUTION,\n",
        "    TUNE_TIME_INTERVAL_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best batch_size: **256** - min: 32 - max: 512\n"
          ]
        }
      ],
      "source": [
        "results = get_results_df(NN_FIRST_STAGE_DEMAND_RESULTS_PATH)\n",
        "\n",
        "best_batch_size = (\n",
        "    results[\n",
        "        (results[\"h3_res\"] == TUNE_H3_RESOLUTION)\n",
        "        & (results[\"time_interval_length\"] == TUNE_TIME_INTERVAL_LENGTH)\n",
        "    ]\n",
        "    .sort_values(by=\"val_mse\", ascending=True)[\"batch_size\"]\n",
        "    .iloc[0]\n",
        ")\n",
        "\n",
        "first_stage_hyperparameters = get_first_stage_hyperparameters()\n",
        "batch_sizes = list(map(lambda x: x['batch_size'], first_stage_hyperparameters))\n",
        "max_batch_size = max(batch_sizes)\n",
        "min_batch_size = min(batch_sizes)\n",
        "\n",
        "print(f\"best batch_size: **{best_batch_size}** - min: {min_batch_size} - max: {max_batch_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find that the best batch size when predicting demand is **256**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the second stage, we find the best architecture of the model by varying the number of layers, nodes and two common hidden activation functions, namely the rectified linear unit and the hyperbolic tangent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acd965e679ad487e8860b3bda777ac35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:21:58] batch_size: 256 - nodes_per_feature: 0.5 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 0.5 - n_layers: 1 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 0.5 - n_layers: 2 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 0.5 - n_layers: 2 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 0.5 - n_layers: 3 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 0.5 - n_layers: 3 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1 - n_layers: 1 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1 - n_layers: 2 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1 - n_layers: 2 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1 - n_layers: 3 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1 - n_layers: 3 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.5 - n_layers: 1 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.5 - n_layers: 1 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.5 - n_layers: 2 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.5 - n_layers: 2 - activation: tanh - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.5 - n_layers: 3 - activation: relu - dropout: -1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.5 - n_layers: 3 - activation: tanh - dropout: -1 # already trained\n"
          ]
        }
      ],
      "source": [
        "get_hyperparameters = lambda : get_second_stage_hyperparameters(best_batch_size)\n",
        "execute_stage(\n",
        "    get_model_data,\n",
        "    NN_SECOND_STAGE_DEMAND_RESULTS_PATH,\n",
        "    get_hyperparameters,\n",
        "    TUNE_H3_RESOLUTION,\n",
        "    TUNE_TIME_INTERVAL_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 256,\n",
              " 'nodes_per_feature': 1.0,\n",
              " 'n_layers': 2,\n",
              " 'activation': 'relu'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = get_results_df(NN_SECOND_STAGE_DEMAND_RESULTS_PATH)\n",
        "best_model = (\n",
        "    results[\n",
        "        (results[\"h3_res\"] == TUNE_H3_RESOLUTION)\n",
        "        & (results[\"time_interval_length\"] == TUNE_TIME_INTERVAL_LENGTH)\n",
        "    ]\n",
        "    .sort_values(by=\"val_mse\", ascending=True)\n",
        "    .iloc[0]\n",
        ")\n",
        "\n",
        "best_config = {\n",
        "    \"batch_size\": best_model[\"batch_size\"],\n",
        "    \"nodes_per_feature\": best_model[\"nodes_per_feature\"],\n",
        "    \"n_layers\": best_model[\"n_layers\"],\n",
        "    \"activation\": best_model[\"activation\"],\n",
        "}\n",
        "\n",
        "best_config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the third stage, we improve the generalizability by adding a dropout layer after every hidden layer and varying the dropout rate between 0 (no dropout) and 0.5 (dropout nodes half of the time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "413acd4f7696440a857007c52a133554",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.0 - n_layers: 2 - activation: relu - dropout: 0 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.0 - n_layers: 2 - activation: relu - dropout: 0.05 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.0 - n_layers: 2 - activation: relu - dropout: 0.1 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.0 - n_layers: 2 - activation: relu - dropout: 0.2 # already trained\n",
            "[19:21:58] batch_size: 256 - nodes_per_feature: 1.0 - n_layers: 2 - activation: relu - dropout: 0.5 # already trained\n"
          ]
        }
      ],
      "source": [
        "get_hyperparameters = lambda : get_third_stage_hyperparameters(\n",
        "    best_batch_size=best_model[\"batch_size\"],\n",
        "    best_nodes_per_feature=best_model[\"nodes_per_feature\"],\n",
        "    best_n_layers=best_model[\"n_layers\"],\n",
        "    best_activation=best_model[\"activation\"],\n",
        ")\n",
        "execute_stage(\n",
        "    get_model_data,\n",
        "    NN_THIRD_STAGE_DEMAND_RESULTS_PATH,\n",
        "    get_hyperparameters,\n",
        "    TUNE_H3_RESOLUTION,\n",
        "    TUNE_TIME_INTERVAL_LENGTH,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 256,\n",
              " 'nodes_per_feature': 1.0,\n",
              " 'n_layers': 2,\n",
              " 'activation': 'relu',\n",
              " 'dropout': 0.5}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = get_results_df(NN_THIRD_STAGE_DEMAND_RESULTS_PATH)\n",
        "best_dropout = (\n",
        "\tresults[\n",
        "\t\t(results[\"h3_res\"] == TUNE_H3_RESOLUTION)\n",
        "\t\t& (results[\"time_interval_length\"] == TUNE_TIME_INTERVAL_LENGTH)\n",
        "\t]\n",
        "\t.sort_values(by=\"val_mse\", ascending=True)[\"dropout\"]\n",
        "\t.iloc[0]\n",
        ")\n",
        "best_config = {\n",
        "\t**best_config,\n",
        "\t\"dropout\": best_dropout,\n",
        "}\n",
        "best_config\n",
        "\t\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we will use these best hyperparameters to train one model for each H3 and time resolution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d1bc3b950c947788bd96a59ec9d432c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "executing h3_res: 7, time_interval_length: 1 done\n",
            "executing h3_res: 7, time_interval_length: 2 done\n",
            "executing h3_res: 7, time_interval_length: 6 done\n",
            "executing h3_res: 7, time_interval_length: 24 done\n",
            "executing h3_res: 8, time_interval_length: 1 done\n",
            "executing h3_res: 8, time_interval_length: 2 done\n",
            "executing h3_res: 8, time_interval_length: 6 done\n",
            "executing h3_res: 8, time_interval_length: 24 done\n",
            "executing h3_res: 9, time_interval_length: 24 done\n"
          ]
        }
      ],
      "source": [
        "for h3_res, time_interval_length in tqdm(\n",
        "    list(product(PREDICTIVE_H3_RESOLUTIONS, CALC_TIME_INTERVAL_LENGTHS))\n",
        "    + ADDITIONAL_PREDICTIVE_RESOLUTIONS\n",
        "):\n",
        "    tqdm.write(f\"executing h3_res: {h3_res}, time_interval_length: {time_interval_length}\", end=\"\\r\")\n",
        "    execute_stage(\n",
        "        get_model_data,\n",
        "        NN_FOURTH_STAGE_DEMAND_RESULTS_PATH,\n",
        "        lambda: [best_config],\n",
        "        h3_res,\n",
        "        time_interval_length,\n",
        "        test_phase=True,\n",
        "        silent=True,\n",
        "    )\n",
        "    tqdm.write(f\"executing h3_res: {h3_res}, time_interval_length: {time_interval_length} done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As an addition we will also train a model that predicts demand for origin-destination pairs instead of just origin. As the dimensionality of the data increases drastically when using origin-destination pairs, we will only use a low h3 resolution (7) and a large time interval (24h)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-07 19:22:04.598087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.601683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.601855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.602365: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-07-07 19:22:04.603186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.603469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.603595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.969953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.970124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.970248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-07 19:22:04.970355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3637 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
            "2022-07-07 19:22:06.249203: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        }
      ],
      "source": [
        "execute_stage(\n",
        "\tlambda _, __: get_demand_orig_dest_model_data(),\n",
        "\tNN_FOURTH_STAGE_DEMAND_RESULTS_PATH,\n",
        "\tlambda : [best_config],\n",
        "\tint(f\"{ORIGIN_DESTINATION_H3_RESOLUTION}{ORIGIN_DESTINATION_H3_RESOLUTION}\"),\n",
        "\tORIGIN_DESTINATION_TIME_INTERVAL_LENGTH,\n",
        "\ttest_phase=True,\n",
        "\tsilent=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>h3_res</th>\n",
              "      <th>time_interval_length</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>nodes_per_feature</th>\n",
              "      <th>n_layers</th>\n",
              "      <th>activation</th>\n",
              "      <th>dropout</th>\n",
              "      <th>train_duration</th>\n",
              "      <th>test_mse</th>\n",
              "      <th>test_rmse</th>\n",
              "      <th>test_mae</th>\n",
              "      <th>test_non_zero_mape</th>\n",
              "      <th>test_zero_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>186.338808</td>\n",
              "      <td>2.112337</td>\n",
              "      <td>1.453388</td>\n",
              "      <td>0.354515</td>\n",
              "      <td>0.415404</td>\n",
              "      <td>0.952907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>118.628595</td>\n",
              "      <td>17.645970</td>\n",
              "      <td>4.200711</td>\n",
              "      <td>1.260489</td>\n",
              "      <td>0.358513</td>\n",
              "      <td>0.917816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>84.846213</td>\n",
              "      <td>121.578570</td>\n",
              "      <td>11.026267</td>\n",
              "      <td>3.922868</td>\n",
              "      <td>0.269336</td>\n",
              "      <td>0.239784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>51.822149</td>\n",
              "      <td>385.978276</td>\n",
              "      <td>19.646330</td>\n",
              "      <td>8.396101</td>\n",
              "      <td>0.180705</td>\n",
              "      <td>0.426461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>827.665968</td>\n",
              "      <td>0.907417</td>\n",
              "      <td>0.952584</td>\n",
              "      <td>0.161567</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.939471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>439.822626</td>\n",
              "      <td>2.682283</td>\n",
              "      <td>1.637768</td>\n",
              "      <td>0.471627</td>\n",
              "      <td>0.519434</td>\n",
              "      <td>0.911342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>203.167135</td>\n",
              "      <td>14.918592</td>\n",
              "      <td>3.862459</td>\n",
              "      <td>1.138881</td>\n",
              "      <td>0.415263</td>\n",
              "      <td>0.922531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>24</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>58.101990</td>\n",
              "      <td>44.829146</td>\n",
              "      <td>6.695457</td>\n",
              "      <td>2.685330</td>\n",
              "      <td>0.267945</td>\n",
              "      <td>0.344550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>24</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>139.595377</td>\n",
              "      <td>8.768210</td>\n",
              "      <td>2.961116</td>\n",
              "      <td>1.323776</td>\n",
              "      <td>0.407589</td>\n",
              "      <td>0.888043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>77</td>\n",
              "      <td>24</td>\n",
              "      <td>256</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.5</td>\n",
              "      <td>492.197467</td>\n",
              "      <td>7.997945</td>\n",
              "      <td>2.828064</td>\n",
              "      <td>0.346599</td>\n",
              "      <td>0.496868</td>\n",
              "      <td>0.958253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   h3_res  time_interval_length  batch_size  nodes_per_feature  n_layers  \\\n",
              "0       7                     1         256                1.0         2   \n",
              "1       7                     2         256                1.0         2   \n",
              "2       7                     6         256                1.0         2   \n",
              "3       7                    24         256                1.0         2   \n",
              "4       8                     1         256                1.0         2   \n",
              "5       8                     2         256                1.0         2   \n",
              "6       8                     6         256                1.0         2   \n",
              "7       8                    24         256                1.0         2   \n",
              "8       9                    24         256                1.0         2   \n",
              "9      77                    24         256                1.0         2   \n",
              "\n",
              "  activation  dropout  train_duration    test_mse  test_rmse  test_mae  \\\n",
              "0       relu      0.5      186.338808    2.112337   1.453388  0.354515   \n",
              "1       relu      0.5      118.628595   17.645970   4.200711  1.260489   \n",
              "2       relu      0.5       84.846213  121.578570  11.026267  3.922868   \n",
              "3       relu      0.5       51.822149  385.978276  19.646330  8.396101   \n",
              "4       relu      0.5      827.665968    0.907417   0.952584  0.161567   \n",
              "5       relu      0.5      439.822626    2.682283   1.637768  0.471627   \n",
              "6       relu      0.5      203.167135   14.918592   3.862459  1.138881   \n",
              "7       relu      0.5       58.101990   44.829146   6.695457  2.685330   \n",
              "8       relu      0.5      139.595377    8.768210   2.961116  1.323776   \n",
              "9       relu      0.5      492.197467    7.997945   2.828064  0.346599   \n",
              "\n",
              "   test_non_zero_mape  test_zero_accuracy  \n",
              "0            0.415404            0.952907  \n",
              "1            0.358513            0.917816  \n",
              "2            0.269336            0.239784  \n",
              "3            0.180705            0.426461  \n",
              "4            1.000000            0.939471  \n",
              "5            0.519434            0.911342  \n",
              "6            0.415263            0.922531  \n",
              "7            0.267945            0.344550  \n",
              "8            0.407589            0.888043  \n",
              "9            0.496868            0.958253  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = get_results_df(NN_FOURTH_STAGE_DEMAND_RESULTS_PATH)\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c6765268434208abe85e0ded45f02f4b14a3cc9f9f7c04b8f035b68c1ed23646"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
